---
title: "Tests of the individual mean response have more power than tests of the area under curve (AUC) in glucose tolerance tests"
author: "Jeffrey A. Walker"
date: "1/11/2020"
output: pdf_document
---

```{r setup, echo=FALSE, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = FALSE)

library(here)
library(ggplot2)
library(ggpubr)
library(cowplot)
library(data.table)

```

```{r functions}
expit <- function(x) {exp(x)/(1+exp(x))} # the inverse logit function. This generates the probability of the event p
logit <- function(p) {log(p/(1-p))} # the log of the odds or "logodds" given the probability of an event p. This is NOT the odds ratio, which is the ratio of two odds.
```

```{r summary functions}
melt_it <- function(res, method_list){
  p_cols <- paste0(method_list, "_p")
  res_long <- melt(res, 
                    id.vars=c("iter", "effect", "baseline_max", "non_baseline_max", "d_baseline", "r.baseline", "abs.r.baseline", "r.nonbaseline", "abs.r.nonbaseline"),
                    measure.vars = p_cols,
                    variable.name = "method",
                    value.name = c("p"))
  res_long[, method := factor(method_list[method], method_list)]
  res_long[, significant := ifelse(p < 0.05, 1, 0)]
  return(res_long)
}

sim_summary <- function(res_long){
  p_summary <- res_long[!is.na(p), .(freq_lt_05 = sum(p < 0.05)/max(iter)),
          by=.(effect, baseline_max, non_baseline_max, method)]
  return(p_summary)
}

```

Researchers most commonly test for a treatment effect on a glucose tolerance curve by either comparing treatment responses at each time point separately, or comparing an area under curve (AUC) composite measure in a single test. Here, I show that a simple comparison of the mean of the post-baseline values with the baseline value as a covariate

1. is a more powerful test. That is, it takes fewer samples to provide sufficient evidence of the direction of the treatment effect.
2. has the expected Type I error rate, while that of the comparison of individual time points is inflated.
3. has the expected Type I error rate conditional on the difference in baseline between treatments, while that of the comparison of AUC increases with the magnitude of the baseline difference.

# methods - make this into a table
area methods
1. auc -- a weighted mean, where weights are a function of the time on either side of the point. Biased effects simply because baseline is part of area. Smaller baseline > more area
2. iauc -- analogous to change score, biased effects. Bigger baseline > more area. Increase 
3. area-cov -- weighted mean but no baseline bias. Should increase precision and power.

mean methods - easy to implement in any stats program.
4. mean - all time points equally weighted. unconditionally unbiased. conditionally biased because of correlation between time points
5. change score -- all time points equally weighted. should increase precision and power but at cost of bias.
6. mean-cov -- all time points equally weighted. increase precision and power.

multivariate -- need R or scripting
7. clda -- models correlation. Equivalent to mean-cov with only one post-baseline time but conditionally biased with multiple.
8. lda-cov -- models correlations. 
9. Roast -- 
10. O'Brien --

# Results
## simulations
1. glucose tolerance effect at times 15, 30, 60
   - run at combos of rho = .3, .8 and cohen = 0, 0.8, 2
2. glucose tolerance effect at times 15 vs. 60 to show consequence of area as weighted mean
   - run at rho=.8 and power = 2
3. glucose tolerance effect at time 15, 30, 60 plus strain effect at time 0 and 120 to show consequence of direct v total effect
   - run at combos of rho = 0.8
   - run at cohen glucose tolerance = 0, 2
   - for cohen_gt = 0, set cohen to 2 and alpha_prime = 0.4, 0, 0, 0, 0
   - for cohen_gt = 2, set coehn to 2 and alpha_prime = 0.4, 1, 1, 1, 0

most relevant result
1. lm-cov and roast have overall best performance: high power without inflated Type I or inflated conditional Type I.

most relevant to researchers using individual tests
2. individual tests have more false positives. If there is some reason to want the estimate at each time point then individual tests okay.

most relevant to researchers using area as response

3. area measures are weighted means. consequence is that some differences are down-weight some up-weighted. consequence on power is that lower power if differences spread across curve, really low power if differences at time 1, but high power if difference in time 3.
4. Mean response and multivariate response have high power and about equal power
5. clda has high power but at cost of high false positive
6. Area has strong conditional bias in probability, consquence that when baseline diff is large due to random sampling, inflated type I. The reason is 1) because area is a function of baseline and 2) correlation between time0 and other times. The later also effects other measures that do not explicitly model baseline value as covariate, most notably mean response. 

Other results
7. clda has high power but at cost of high type I
8. clda is conditionally biased by baseline, despite the equivalency of clda and lm-cov when there is only one post-baseline time point.

```{r}
mu <- c(148, 230, 230, 200, 146) # mu of control in perinatal lead
emp.sigma.ratio <- c(0.12, 0.3, 0.3, 0.3, 0.3) # rougly median of empirical
emp.sigma <- emp.sigma.ratio*(mu[2]-mu[1])

```

## Type I error and power (Simulation 1)
```{r simulation-1-import}
fn <- "simulation-1.Le6N9.Rds" #
file_path <- here(output_path, fn)
sim1 <- data.table(readRDS(file_path))
method_list <- c("lm_area", "lm_base", "lm_cov", "lm_mean", "lm_mean_change", "lm_mean_cov", "multi_t", "obrien", "roast", "rmanova", "clda", "lda_cov")

# bonferroni rmanova and multi_t
sim1[, rmanova_p:=ifelse(rmanova_p*4>1,1,rmanova_p*4)]
sim1[, multi_t_p:=ifelse(multi_t_p*4>1,1,multi_t_p*4)]

sim1_long <- melt_it(sim1, method_list)

sim1_sum <- sim_summary(sim1_long)
sim1_sum[, Rho_combis:=factor(paste(baseline_max, non_baseline_max, sep=", "))]
sim1_sum[, Rho_model:=factor(as.integer(Rho_combis))]
```

### Unconditional Type I error & power

```{r simulatio-1-unconditional}
jco_pal <- pal_jco()(6)
#scales::show_col(jco_pal)

group_colors <- c(rep(jco_pal[c(2,5,4,6)], each=3))[1:length(method_list)]
group_shapes <- c(rep(c(15, 16, 17), 4))[1:length(method_list)]
  
pd <- position_dodge(0.8)
gg1 <- ggplot(data = sim1_sum,
       aes(x=1, y=freq_lt_05, color=method, shape=method)) +
  geom_point(position = pd) +
  scale_color_manual(values = group_colors) +
  scale_shape_manual(values = group_shapes) +
  facet_grid(. ~ effect, scales = "free_y", labeller = "label_both") +
  ylab("Frequency p < 0.05") +
  xlab("") +
  theme_pubr() +
  theme(legend.position="bottom",
        axis.text.x = element_blank()) +
  guides(col = guide_legend(ncol = 4)) +
  NULL
gg1
```

## Type I error conditional on false initial difference (simulation 1)

```{r simulation-1-conditional}
jco_pal1 <- pal_jco()(6)
group_colors <- c(rep(jco_pal[c(2,5,4,6)], each=3))[1:length(method_list)]
group_shapes <- c(rep(c(15, 16, 17), 4))[1:length(method_list)]

subdata <- sim1_long[effect == "0",]
subdata[, d_baseline_std := abs(d_baseline)/emp.sigma]
subdata[, logit_p := ifelse(is.infinite(logit(p)), NA, logit(p))]
plot_data <- data.table(NULL)
new_x <- seq(0, 1.5, by=0.1) # uniform values of d_baseline_std for prediction
new_data <- data.table(d_baseline_std = new_x)
for(method_i in method_list){
  m1 <- glm(significant ~ d_baseline_std, 
            family = binomial(link="logit"), 
            data=subdata[method==method_i])
  prob.m1 <- predict(m1, new_data, type="response")
  m2 <- lm(logit_p ~ d_baseline_std, 
           data=subdata[method==method_i])
  prob.m2 <- expit(predict(m2, new_data))
  plot_data <- rbind(plot_data, data.table(method = method_i,
                                           d_baseline_std = new_x, 
                                           prob.m1=prob.m1,
                                           prob.m2=prob.m2))
}

plot_data[, method := factor(method, method_list)]
gg1 <- ggplot(data=plot_data,
              aes(x=d_baseline_std, y=prob.m1, color=method, shape=method)) +
  geom_hline(yintercept = 0.05, linetype = "dashed", alpha=0.5) +
  geom_point() +
  geom_line() +
  scale_color_manual(values = group_colors) +
  scale_shape_manual(values = group_shapes) +
  ylab("Probability of p < 0.05") +
  xlab("Difference at Time0 (in standard deviation units)") +
  theme_pubr() +
  theme(legend.position="top") +
  guides(col = guide_legend(ncol = 4)) +
  NULL
gg1

gg2 <- ggplot(data=plot_data,
              aes(x=d_baseline_std, y=prob.m2, color=method, shape=method)) +
  geom_hline(yintercept = 0.05, linetype = "dashed", alpha=0.5) +
  geom_point() +
  geom_line() +
  scale_color_manual(values = group_colors) +
  scale_shape_manual(values = group_shapes) +
  ylab("Probability of p < 0.05") +
  xlab("Difference at Time0 (in standard deviation units)") +
  theme_pubr() +
  theme(legend.position="top") +
  guides(col = guide_legend(ncol = 4)) +
  NULL
#gg2
```

## Effect of correlation on conditional Type I error (Simulation 2)

```{r simulation-2-import}
fn <- "simulation-2.YonKI.Rds" #
file_path <- here(output_path, fn)
sim2 <- data.table(readRDS(file_path))
method_list <- c("lm_area", "lm_base", "lm_cov", "lm_mean", "lm_mean_change", "lm_mean_cov", "multi_t", "obrien", "roast", "rmanova", "clda", "lda_cov")

# bonferroni rmanova and multi_t
sim2[, rmanova_p:=ifelse(rmanova_p*4>1,1,rmanova_p*4)]
sim2[, multi_t_p:=ifelse(multi_t_p*4>1,1,multi_t_p*4)]
sim2_long <- melt_it(sim2, method_list)

# add sim1 data
sim2_long <- rbind(sim1_long[effect=="0"], sim2_long)
sim2_long[, R_model := factor(as.integer(factor(paste(baseline_max, non_baseline_max, sep=", "))))]

sim2_long[, .(baseline=mean(r.baseline),
              non_baseline=mean(r.nonbaseline)),
          by = .(R_model)]
```

```{r simulation-2-conditional}
jco_pal1 <- pal_jco()(6)
group_colors <- c(rep(jco_pal[c(2,5,4,6)], each=3))[1:length(method_list)]
group_shapes <- c(rep(c(15, 16, 17), 4))[1:length(method_list)]

sim2_long[, d_baseline_std := abs(d_baseline)/emp.sigma]
sim2_long[, logit_p := ifelse(is.infinite(logit(p)), NA, logit(p))]
plot_data <- data.table(NULL)
new_d_baseline <- seq(0, 1.5, by=0.1) # uniform values of d_baseline_std for prediction
new_data <- data.table(d_baseline_std = new_d_baseline)
for(model_i in levels(sim2_long$R_model)){
  for(method_i in method_list){
    m1 <- glm(significant ~ d_baseline_std, 
              family = binomial(link="logit"), 
              data=sim2_long[method==method_i & R_model==model_i])
    prob.m1 <- predict(m1, new_data, type="response")
    plot_data <- rbind(plot_data, data.table(method = method_i,
                                             R_model = model_i,
                                             d_baseline_std = new_d_baseline, 
                                             prob.m1=prob.m1))
  }
}

plot_data[, method := factor(method, method_list)]
gg1 <- ggplot(data=plot_data,
              aes(x=d_baseline_std, y=prob.m1, color=method, shape=method)) +
  geom_hline(yintercept = 0.05, linetype = "dashed", alpha=0.5) +
  geom_point() +
  geom_line() +
  scale_color_manual(values = group_colors) +
  scale_shape_manual(values = group_shapes) +
  ylab("Probability of p < 0.05") +
  xlab("Difference at Time0 (in standard deviation units)") +
  theme_pubr() +
  theme(legend.position="top") +
  guides(col = guide_legend(ncol = 4)) +
  facet_grid(.~R_model, labeller = "label_both") +
  NULL
gg1


```

## Consequence of location of effect (simulation 2)

```{r fig-freq-lt-05}
jco_pal1 <- pal_jco()(6)
#scales::show_col(jco_pal)

group_colors <- c(rep(jco_pal[c(2,1,4)], each=3), jco_pal[4], jco_pal[4])[1:length(method_list)]
group_shapes <- c(rep(c(15, 16, 17), 3), 18, 19)[1:length(method_list)]
  
pd <- position_dodge(0.8)
gg1 <- ggplot(data = res_summary[time_model=="standard" & rmax=="0.8"],
       aes(x=effect_model, y=freq_lt_05, color=method, shape=method)) +
  geom_point(position = pd) +
  scale_color_manual(values = group_colors) +
  scale_shape_manual(values = group_shapes) +
  facet_grid(. ~ effect, scales = "free_y", labeller = "label_both") +
  ylab("Frequency p < 0.05") +
  xlab("At what time is effect present?") +
  theme_pubr() +
  theme(legend.position="bottom") +
 # guides(col = guide_legend(ncol = 3)) +
  guides(col = guide_legend(ncol = 4)) +
  NULL
gg1
```

## Consequence true initial effect on of Type I error (simulation 3)

```{r}
```

## Consequence of pattern of effect on rmanova (simulation 4)
```{r}
res[, multi_t_adj_p := multi_t_p*4]
res[, rmanova_adj_p := rmanova_p*4]
method_list.4 <- c(method_list, "multi_t_adj", "rmanova_adj")
p_cols.4 <- paste0(method_list.4, "_p")
res_table <- melt(res, 
                  id.vars=c("iter","rmax", "effect","effect_model", "time_model", "d_baseline"),
                  measure.vars = p_cols.4,
                  variable.name = "method",
                  value.name = c("p"))
res_table[, method := factor(method_list.4[method], method_list.4)]
res_table[, significant := ifelse(p < 0.05, 1, 0)]

res_summary <- res_table[!is.na(p), .(freq_lt_05 = sum(p < 0.05)/max(iter),
                       rmse_theta = sqrt(mean((theta-b)^2))),
          by=.(effect_model, time_model, method, effect, rmax)]

```

```{r}
jco_pal1 <- pal_jco()(6)
#scales::show_col(jco_pal)

group_colors <- c(rep(jco_pal[c(2,1,4)], each=3), jco_pal[4], jco_pal[4])[1:length(method_list)]
group_shapes <- c(rep(c(15, 16, 17), 3), 18, 19)[1:length(method_list)]
  
gg1 <- ggplot(data = res_summary[effect_model=="time1-2r"],
       aes(x=effect_model, y=freq_lt_05, color=method, shape=method)) +
  geom_hline(yintercept = 0.05, linetype = "dashed", alpha=0.5) +
  geom_point(position = pd, size = 2) +
  scale_color_manual(values = group_colors) +
  scale_shape_manual(values = group_shapes) +
  ylab("Frequency p < 0.05") +
  xlab("Method") +
  theme_pubr() +
  theme(legend.position="bottom") +
 # guides(col = guide_legend(ncol = 3)) +
  guides(col = guide_legend(ncol = 4)) +
  NULL
#gg1

gg2 <- ggplot(data = res_summary[effect_model=="time0"],
       aes(x=effect_model, y=freq_lt_05, color=method, shape=method)) +
  geom_hline(yintercept = 0.05, linetype = "dashed", alpha=0.5) +
  geom_point(position = pd, size = 2) +
  scale_color_manual(values = group_colors) +
  scale_shape_manual(values = group_shapes) +
  ylab("Frequency p < 0.05") +
  xlab("Method") +
  theme_pubr() +
  theme(legend.position="bottom") +
 # guides(col = guide_legend(ncol = 3)) +
  guides(col = guide_legend(ncol = 4)) +
  NULL
#gg2
plot_grid(gg1, gg2, labels="AUTO")
```


## difference at baseline

```{r}
jco_pal1 <- pal_jco()(6)
group_colors <- c(rep(jco_pal[c(2,1,4)], each=3), jco_pal[4], jco_pal[4])[1:length(method_list)]
group_shapes <- c(rep(c(15, 16, 17), 3), 18, 19)[1:length(method_list)]
  
pd <- position_dodge(0.8)
gg1 <- ggplot(data = res_summary,
       aes(x=method, y=freq_lt_05, color=method, shape=method)) +
  geom_hline(yintercept = 0.05, linetype = "dashed", alpha=0.5) +
  geom_point(position = pd) +
  scale_color_manual(values = group_colors) +
  scale_shape_manual(values = group_shapes) +
  facet_grid(. ~ effect, scales = "free_y", labeller = "label_both") +
  ylab("Frequency p < 0.05") +
  xlab("") +
  theme_pubr() +
  theme(legend.position="bottom",
        axis.text.x = element_blank()) +
  guides(col = guide_legend(ncol = 4)) +
  facet_grid(. ~ effect_model, scales = "free_y") +
  NULL
gg1
```

```{r}
jco_pal1 <- pal_jco()(6)
group_colors <- c(rep(jco_pal[c(2,1,4)], each=3), jco_pal[4], jco_pal[4])[1:length(method_list)]
group_shapes <- c(rep(c(15, 16, 17), 3), 18, 19)[1:length(method_list)]

subdata <- res_table[effect_model == "time0"]
subdata[, d_baseline_std := abs(d_baseline)/sd(d_baseline)]
subdata[, logit_p := ifelse(is.infinite(logit(p)), NA, logit(p))]
plot_data <- data.table(NULL)
new_x <- seq(0,4, by=0.1) # uniform values of d_baseline_std for prediction
new_data <- data.table(d_baseline_std = new_x)
for(rmax_i in unique(subdata$rmax)){
  for(method_i in method_list){
    m1 <- glm(significant ~ d_baseline_std, 
              family = binomial(link="logit"), 
              data=subdata[method==method_i & rmax == rmax_i])
    prob.m1 <- predict(m1, new_data, type="response")
    m2 <- lm(logit_p ~ d_baseline_std, 
             data=subdata[method==method_i & rmax == rmax_i])
    prob.m2 <- expit(predict(m2, new_data))
    plot_data <- rbind(plot_data, data.table(method = method_i,
                                             rmax = rmax_i,
                                             d_baseline_std = new_x, 
                                             prob.m1=prob.m1,
                                             prob.m2=prob.m2))
  }
}
plot_data[, method := factor(method, method_list)]
gg1 <- ggplot(data=plot_data,
              aes(x=d_baseline_std, y=prob.m1, color=method, shape=method)) +
  geom_hline(yintercept = 0.05, linetype = "dashed", alpha=0.5) +
  geom_point() +
  geom_line() +
  scale_color_manual(values = group_colors) +
  scale_shape_manual(values = group_shapes) +
  ylab("Probability of p < 0.05") +
  xlab("Difference at Time0 (in standard deviation units)") +
  theme_pubr() +
  theme(legend.position="top") +
  guides(col = guide_legend(ncol = 4)) +
  facet_grid(. ~ rmax, labeller = "label_both") +
  NULL
gg1

gg2 <- ggplot(data=plot_data,
              aes(x=d_baseline_std, y=prob.m2, color=method, shape=method)) +
  geom_hline(yintercept = 0.05, linetype = "dashed", alpha=0.5) +
  geom_point() +
  geom_line() +
  scale_color_manual(values = group_colors) +
  scale_shape_manual(values = group_shapes) +
  ylab("Probability of p < 0.05") +
  xlab("Difference at Time0 (in standard deviation units)") +
  theme_pubr() +
  theme(legend.position="top") +
  guides(col = guide_legend(ncol = 4)) +
  NULL
#gg2
```

