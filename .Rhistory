sim_stats[iter, "lm_mean_cov_alpha_p"] <- p_z
#sim_stats[iter, "lm_mean_cov_b"] <- coef(m5)["treatmenttr"]
}
if("lm_mean_change" %in% method_list){
m6 <- lm(glucose_change ~ treatment, data=fd)
sim_stats[iter, "lm_mean_change_p"] <- coef(summary(m6))["treatmenttr","Pr(>|t|)"]
#sim_stats[iter, "lm_mean_change_b"] <- coef(m6)["treatmenttr"]
}
if("rmanova" %in% method_list |
"rmanova.i" %in% method_list |
"rmanova.t" %in% method_list){
# rmanova returns the smallest unadjusted p of the pairs
# rmanova.i returns the p for the anova interaction
# rmanova.t returns the p for the anova treatment
m7 <- aov_4(glucose ~ time*treatment + (time|id),
data=fd_long)
if("rmanova" %in% method_list){
m7.emm <- emmeans(m7,  ~ treatment*time)
sim_stats[iter, "rmanova_p"] <- min(summary(emmeans::contrast(m7.emm,
method = "revpairwise",
simple = "each",
combine = TRUE,
adjust = "none"))[2:n.times, "p.value"])
}
if("rmanova.i" %in% method_list){
sim_stats[iter, "rmanova.i_p"] <- m7$anova_table["treatment:time", "Pr(>F)"]}
if("rmanova.t" %in% method_list){
sim_stats[iter, "rmanova.t_p"] <- m7$anova_table["treatment", "Pr(>F)"]}
}
if("multi_t" %in% method_list){
Yy <- Y[, -1]
fit <- lm(Yy ~ treatment, data=fd_wide)
sim_stats[iter, "multi_t_p"] <- min(
coefficients(summary(fit))[[1]]["treatmenttr","Pr(>|t|)"],
coefficients(summary(fit))[[2]]["treatmenttr","Pr(>|t|)"],
coefficients(summary(fit))[[3]]["treatmenttr","Pr(>|t|)"],
coefficients(summary(fit))[[4]]["treatmenttr","Pr(>|t|)"]
)
#sim_stats[iter, "multi_t_b"] <- NA
}
if("clda" %in% method_list){
# clda
#      design <- model.matrix( ~ time + treatment:time, data=fd_long)
# remove intercept column and effect of tr at time 0
#      X <- design[, -c(1, which(colnames(design) == "timeglucose0:treatmenttr"))]
# first check equivalence with single post baseline time
check_equivalence <- FALSE
if(check_equivalence == TRUE){
inc <- which(fd_long$time=="glucose0" | fd_long$time=="glucose15")
X.check <- design[inc, c(2,7)]
m8a <- gls(glucose ~ X.check, # clda
data = fd_long[time=="glucose0" | time=="glucose15"],
weights = varIdent(form= ~ 1 | time),
correlation= corSymm(form=~ 1| id)
)
m8b <- lm(glucose ~ glucose_0 + treatment, # ancova-like
data = fd_long[time=="glucose15"]
)
coef(summary(m8a))
coef(summary(m8b))
# note that clda has smaller SE.
# from https://datascienceplus.com/taking-the-baseline-measurement-into-account-constrained-lda-in-r/. By setting weights = varIdent(form = ~ 1 | Time) a separate standard deviation will be estimated for each time point and a seperate correlation will be estimated for each pair of time points (= unstructured variance covariance matrix). By setting weights = varIdent(form = ~ 1 | Time:Group), a separate variance is estimated for each combination of Group and Time (Pre-Exp Post-Exp Pre-Con Post-Con ). The argument correlation=corSymm (form = ~ 1 | Id) defines the subject levels. The correlation structure is assumed to apply only to observations within the same subject (in our example: Id); observations from different subjects (a different value for Id) are assumed to be uncorrelated.
}
#      m8 <- gls(glucose ~ X,
#                 data = fd_long,
#                 weights = varIdent(form= ~ 1 | time),
#                 correlation= corSymm(form=~ 1| id))
# # an alternative that gives same results. Simply code the interaction columns into a factor
fd_clda <- copy(fd_long)
fd_clda[, time.treatment := ifelse(time != "glucose0" & treatment=="tr", paste0(time, ":tr"), "cont")]
fd_clda[, time.treatment := factor(time.treatment, c("cont","glucose15:tr", "glucose30:tr",  "glucose60:tr", "glucose120:tr"))]
m8 <- gls(glucose ~ time + time.treatment,
data = fd_clda,
weights = varIdent(form= ~ 1 | time),
correlation= corSymm(form=~ 1| id))
r_fit <- cov2cor(getVarCov(m8))
r_bar <- mean(r_fit[upper.tri(r_fit)])
m <- round(5*n*2/(1 + r_bar*(5-1)), 0)
#m8.z <- summary(glht(m8, matrix(c(0, 0,0,0,0,1,1,1,1), 1)))
m8.t <- summary(glht(m8,
matrix(c(0, 0,0,0,0,1,1,1,1), 1),
df = m - p.clda))
sim_stats[iter, "clda_p"] <- m8.t$test$pvalues
#sim_stats[iter, "clda_b"] <- m8.t$test$coefficients/4
}
if("lda_cov" %in% method_list){
subdata <- fd_long[time != "glucose0"] # needed for emmeans
m9 <- gls(glucose ~ time*treatment + glucose_0,
data = subdata,
weights = varIdent(form= ~ 1 | time),
correlation= corSymm(form=~ 1 | id))
# note interaction coefficients are not effects at times 30, 60, 120
# but differences in effect from that at time 15. This is *not* what we want.
m9.emm <- emmeans(m9,
specs=c("treatment"),
#                      mode = "boot-satterthwaite",
mode = "df.error",
data = subdata)
m9.trt <- emmeans::contrast(m9.emm, method="revpairwise")
sim_stats[iter, "lda_cov_p"] <- summary(m9.trt)[, "p.value"]
#sim_stats[iter, "lda_cov_b"] <- summary(m9.trt)[, "estimate"]
}
if("roast" %in% method_list){
Yt <- t(Y[, -1]) # responses in rows
design <- model.matrix(roast_form, data=fd_wide)
colnames(design)[1] <- 'Intercept' # change '(Intercept)' to 'Intercept'
prob <- roast(y=Yt,design=design,contrast=2, nrot=2000)$p['UpOrDown','P.Value']
sim_stats[iter, "roast_p"] <- roast(y=Yt,design=design,contrast=2, nrot=2000)$p['UpOrDown','P.Value']
#sim_stats[iter, "roast_b"] <- NA
# cont.matrix <- makeContrasts(delta="zhedonia-zeudaimonia",levels=design)
# prob['delta'] <- roast(y=Yt,design=design,contrast=cont.matrix, nrot=perms)$p['UpOrDown','P.Value']
}
if("obrien" %in% method_list){
Yy <- Y[, -1]
# design matrix for obrien
X2 <- model.matrix(~ glucose0, data=fd_wide)
XTXI <- solve(t(X2)%*%X2)
fit <- lm.fit(X2, Yy)
e <- fit$residuals
ranks <- apply(e, 2, rank)
ranksum <- apply(ranks, 1, sum)
obrien.p <- t.test(ranksum ~ fd_wide$treatment, var.equal=TRUE)$p.value
# wilcox.test(ranksum ~ fd_wide$treatment)
# rank2 <- apply(e, 1, sum)
# wilcox.test(rank2 ~ fd_wide$treatment)
sim_stats[iter, "obrien_p"] <- obrien.p
#sim_stats[iter, "obrien_b"] <- NA
}
}
return(sim_stats)
}
simulation_wrapper <- function(
niter = 1000,
n = 5,
method_list,
times = c(0, 15, 30, 60, 120),
gtt_effects = c(0, 1, 1, 1, 0), # added effect of gtt
pre_effect = 0, # effect that would occur without gtt
mu,
sigma,
cohen_list = c(0, 0.8, 2),
cor_models
){
p <- length(times)
combis <- expand.grid(cohen = cohen_list, cor_model = 1:nrow(cor_models))
for(i in 1:nrow(combis)){
cohen <- combis[i, "cohen"]
baseline_max <- cor_models[combis[i, "cor_model"], "baseline_max"]
non_baseline_max <- cor_models[combis[i, "cor_model"], "non_baseline_max"]
R <- fake_Rho(p,
rho.base.2 = baseline_max,
rho.base.p = 3/4*baseline_max,
rho.max.max = non_baseline_max,
rho.max.min = 7/8*non_baseline_max,
rho.min = 5/8*non_baseline_max)
R_0 <- R[,1] # correlation of each time with time0
R_0[1] <- 0 # don't add this component to first beta
Sigma <- diag(sigma)%*%R%*%diag(sigma)
# total = direct + indirect
beta_1 <- R_0*sigma/sigma[1]
beta <- gtt_effects*cohen*sigma
alpha <- pre_effect*cohen*sigma[1]
sim_stats <- simulate_it(n = n,
mu = mu,
beta = beta,
alpha = alpha,
Sigma = Sigma,
times = times,
niter = niter,
method_list = method_list)
res <- rbind(res, data.table(iter = 1:niter,
effect = cohen,
baseline_max = baseline_max,
non_baseline_max = non_baseline_max,
data.table(sim_stats)))
}
res[, effect := factor(effect)]
res[, baseline_max := factor(baseline_max)]
res[, non_baseline_max := factor(non_baseline_max)]
return(res)
}
n <- 6 # sample per treatment level
p = 5 # number of time periods
niter <- 2000 # number of iterations in simulation per parameter combination
# empirical response mean
mu <- c(148, 230, 230, 200, 146) # mu of control in perinatal lead
emp.sigma.ratio <- c(0.12, 0.3, 0.3, 0.3, 0.3) # rougly median of empirical
emp.sigma <- emp.sigma.ratio*(mu[2]-mu[1])
expit <- function(x) {exp(x)/(1+exp(x))} # the inverse logit function. This generates the probability of the event p
logit <- function(p) {log(p/(1-p))} # the log of the odds or "logodds" given the probability of an event p. This is NOT the odds ratio, which is the ratio of two odds.
melt_it <- function(res, method_list){
p_cols <- paste0(method_list, "_p")
res_long <- melt(res,
id.vars=c("iter", "effect_model", "effect", "baseline_max", "non_baseline_max", "d_baseline", "r.baseline", "abs.r.baseline", "r.nonbaseline", "abs.r.nonbaseline"),
measure.vars = p_cols,
variable.name = "method",
value.name = c("p"))
res_long[, method := factor(method_list[method], method_list)]
res_long[, significant := ifelse(p < 0.05, 1, 0)]
return(res_long)
}
sim_summary <- function(res_long){
p_summary <- res_long[!is.na(p), .(freq_lt_05 = sum(p < 0.05)/max(iter)),
by=.(effect, baseline_max, non_baseline_max, method, effect_model)]
return(p_summary)
}
fn <- "simulation-1.Le6N9.Rds" #
file_path <- here(output_path, fn)
sim1 <- data.table(readRDS(file_path))
method_list <- c("lm_area", "lm_base", "lm_cov", "lm_mean", "lm_mean_change", "lm_mean_cov", "multi_t", "obrien", "roast", "rmanova", "clda", "lda_cov")
# bonferroni rmanova and multi_t
sim1[, rmanova_p:=ifelse(rmanova_p*4>1,1,rmanova_p*4)]
sim1[, multi_t_p:=ifelse(multi_t_p*4>1,1,multi_t_p*4)]
sim1_long <- melt_it(sim1, method_list)
head(sim1)
fn <- "simulation-1.Le6N9.Rds" #
file_path <- here(output_path, fn)
sim1 <- data.table(readRDS(file_path))
method_list <- c("lm_area", "lm_base", "lm_cov", "lm_mean", "lm_mean_change", "lm_mean_cov", "multi_t", "obrien", "roast", "rmanova", "clda", "lda_cov")
# bonferroni rmanova and multi_t
sim1[, rmanova_p:=ifelse(rmanova_p*4 > 1, 1, rmanova_p*4)]
sim1[, multi_t_p:=ifelse(multi_t_p*4 > 1, 1, multi_t_p*4)]
p_cols <- paste0(method_list, "_p")
sim1_long <- melt(res,
id.vars=c("iter", "effect", "baseline_max", "non_baseline_max", "d_baseline", "r.baseline", "abs.r.baseline", "r.nonbaseline", "abs.r.nonbaseline"),
measure.vars = p_cols,
variable.name = "method",
value.name = c("p"))
fn <- "simulation-1.Le6N9.Rds" #
file_path <- here(output_path, fn)
sim1 <- data.table(readRDS(file_path))
method_list <- c("lm_area", "lm_base", "lm_cov", "lm_mean", "lm_mean_change", "lm_mean_cov", "multi_t", "obrien", "roast", "rmanova", "clda", "lda_cov")
# bonferroni rmanova and multi_t
sim1[, rmanova_p:=ifelse(rmanova_p*4 > 1, 1, rmanova_p*4)]
sim1[, multi_t_p:=ifelse(multi_t_p*4 > 1, 1, multi_t_p*4)]
p_cols <- paste0(method_list, "_p")
sim1_long <- melt(sim1,
id.vars=c("iter", "effect", "baseline_max", "non_baseline_max", "d_baseline", "r.baseline", "abs.r.baseline", "r.nonbaseline", "abs.r.nonbaseline"),
measure.vars = p_cols,
variable.name = "method",
value.name = c("p"))
sim1_long[, method := factor(method_list[method], method_list)]
sim1_long[, significant := ifelse(p < 0.05, 1, 0)]
sim1_sum <- sim_summary(sim1_long)
melt_it <- function(res, method_list){
p_cols <- paste0(method_list, "_p")
res_long <- melt(res,
id.vars=c("iter", "effect", "baseline_max", "non_baseline_max", "d_baseline", "r.baseline", "abs.r.baseline", "r.nonbaseline", "abs.r.nonbaseline"),
measure.vars = p_cols,
variable.name = "method",
value.name = c("p"))
res_long[, method := factor(method_list[method], method_list)]
res_long[, significant := ifelse(p < 0.05, 1, 0)]
return(res_long)
}
sim_summary <- function(res_long){
p_summary <- res_long[!is.na(p), .(freq_lt_05 = sum(p < 0.05)/max(iter)),
by=.(effect, baseline_max, non_baseline_max, method, effect_model)]
return(p_summary)
}
fn <- "simulation-1.Le6N9.Rds" #
file_path <- here(output_path, fn)
sim1 <- data.table(readRDS(file_path))
method_list <- c("lm_area", "lm_base", "lm_cov", "lm_mean", "lm_mean_change", "lm_mean_cov", "multi_t", "obrien", "roast", "rmanova", "clda", "lda_cov")
# bonferroni rmanova and multi_t
sim1[, rmanova_p:=ifelse(rmanova_p*4 > 1, 1, rmanova_p*4)]
sim1[, multi_t_p:=ifelse(multi_t_p*4 > 1, 1, multi_t_p*4)]
sim1_long <- melt_it(sim1, method_list)
sim1_sum <- sim_summary(sim1_long)
fn <- "simulation-4.dyUoA.Rds"
file_path <- here(output_path, fn)
sim4 <- data.table(readRDS(file_path))
sim4[, lm_mean_cov_alpha_p:=NULL]
# add simulation 1
fn <- "simulation-1.Le6N9.Rds"
file_path <- here(output_path, fn)
sim1b <- data.table(readRDS(file_path))[effect=="0"]
sim1b[, effect_model:="no pre"]
sim4 <- rbind(sim4, sim1b)
sim4[, effect_model := factor(effect_model)]
method_list <- c("lm_area", "lm_base", "lm_cov", "lm_mean", "lm_mean_change", "lm_mean_cov", "multi_t",  "rmanova", "clda", "lda_cov", "obrien", "roast")
# bonferroni rmanova and multi_t
sim4[, rmanova_p:=ifelse(rmanova_p*4>1,1,rmanova_p*4)]
sim4[, multi_t_p:=ifelse(multi_t_p*4>1,1,multi_t_p*4)]
sim4_long <- melt_it(sim4, method_list)
sim4_long[!is.na(p), .(freq_lt_05 = sum(p < 0.05)/max(iter)),
by=.(effect_model, method)]
names(sim4)
unique(sim4$effect_model)
melt_it <- function(res, method_list){
p_cols <- paste0(method_list, "_p")
if("effect_model" !%in% names(res)){
names(rs)
names(res)
res <- sim1
names(res)
?setdiff
"effect_model" %in% names(res)
"effect_model" !%in% names(res)
"effect_model" %nin% names(res)
melt_it <- function(res, method_list){
p_cols <- paste0(method_list, "_p")
if("effect_model" %nin% names(res)){ #%nin% from Hmisc
res[, effect_model := "none"]
}
res_long <- melt(res,
id.vars=c("iter", "effect_model", "effect", "baseline_max", "non_baseline_max", "d_baseline", "r.baseline", "abs.r.baseline", "r.nonbaseline", "abs.r.nonbaseline"),
measure.vars = p_cols,
variable.name = "method",
value.name = c("p"))
res_long[, method := factor(method_list[method], method_list)]
res_long[, significant := ifelse(p < 0.05, 1, 0)]
return(res_long)
}
sim_summary <- function(res_long){
p_summary <- res_long[!is.na(p), .(freq_lt_05 = sum(p < 0.05)/max(iter)),
by=.(effect, baseline_max, non_baseline_max, method, effect_model)]
return(p_summary)
}
fn <- "simulation-1.Le6N9.Rds" #
file_path <- here(output_path, fn)
sim1 <- data.table(readRDS(file_path))
method_list <- c("lm_area", "lm_base", "lm_cov", "lm_mean", "lm_mean_change", "lm_mean_cov", "multi_t", "obrien", "roast", "rmanova", "clda", "lda_cov")
# bonferroni rmanova and multi_t
sim1[, rmanova_p:=ifelse(rmanova_p*4 > 1, 1, rmanova_p*4)]
sim1[, multi_t_p:=ifelse(multi_t_p*4 > 1, 1, multi_t_p*4)]
sim1_long <- melt_it(sim1, method_list)
sim1_sum <- sim_summary(sim1_long)
sim1_sum[, Rho_combis:=factor(paste(baseline_max, non_baseline_max, sep=", "))]
sim1_sum[, Rho_model:=factor(as.integer(Rho_combis))]
jco_pal <- pal_jco()(6)
#scales::show_col(jco_pal)
group_colors <- c(rep(jco_pal[c(2,5,4,6)], each=3))[1:length(method_list)]
group_shapes <- c(rep(c(15, 16, 17), 4))[1:length(method_list)]
pd <- position_dodge(0.8)
gg1 <- ggplot(data = sim1_sum,
aes(x=1, y=freq_lt_05, color=method, shape=method)) +
geom_point(position = pd) +
scale_color_manual(values = group_colors) +
scale_shape_manual(values = group_shapes) +
facet_grid(. ~ effect, scales = "free_y", labeller = "label_both") +
ylab("Frequency p < 0.05") +
xlab("") +
theme_pubr() +
theme(legend.position="bottom",
axis.text.x = element_blank()) +
guides(col = guide_legend(ncol = 4)) +
NULL
gg1
jco_pal1 <- pal_jco()(6)
group_colors <- c(rep(jco_pal[c(2,5,4,6)], each=3))[1:length(method_list)]
group_shapes <- c(rep(c(15, 16, 17), 4))[1:length(method_list)]
subdata <- sim1_long[effect == "0",]
subdata[, d_baseline_std := abs(d_baseline)/emp.sigma]
subdata[, logit_p := ifelse(is.infinite(logit(p)), NA, logit(p))]
plot_data <- data.table(NULL)
new_x <- seq(0, 1.5, by=0.1) # uniform values of d_baseline_std for prediction
new_data <- data.table(d_baseline_std = new_x)
for(method_i in method_list){
m1 <- glm(significant ~ d_baseline_std,
family = binomial(link="logit"),
data=subdata[method==method_i])
prob.m1 <- predict(m1, new_data, type="response")
m2 <- lm(logit_p ~ d_baseline_std,
data=subdata[method==method_i])
prob.m2 <- expit(predict(m2, new_data))
plot_data <- rbind(plot_data, data.table(method = method_i,
d_baseline_std = new_x,
prob.m1=prob.m1,
prob.m2=prob.m2))
}
plot_data[, method := factor(method, method_list)]
gg1 <- ggplot(data=plot_data,
aes(x=d_baseline_std, y=prob.m1, color=method, shape=method)) +
geom_hline(yintercept = 0.05, linetype = "dashed", alpha=0.5) +
geom_point() +
geom_line() +
scale_color_manual(values = group_colors) +
scale_shape_manual(values = group_shapes) +
ylab("Probability of p < 0.05") +
xlab("Difference at Time0 (in standard deviation units)") +
theme_pubr() +
theme(legend.position="top") +
guides(col = guide_legend(ncol = 4)) +
NULL
gg1
gg2 <- ggplot(data=plot_data,
aes(x=d_baseline_std, y=prob.m2, color=method, shape=method)) +
geom_hline(yintercept = 0.05, linetype = "dashed", alpha=0.5) +
geom_point() +
geom_line() +
scale_color_manual(values = group_colors) +
scale_shape_manual(values = group_shapes) +
ylab("Probability of p < 0.05") +
xlab("Difference at Time0 (in standard deviation units)") +
theme_pubr() +
theme(legend.position="top") +
guides(col = guide_legend(ncol = 4)) +
NULL
#gg2
fn <- "simulation-2.YonKI.Rds" #
file_path <- here(output_path, fn)
sim2 <- data.table(readRDS(file_path))
method_list <- c("lm_area", "lm_base", "lm_cov", "lm_mean", "lm_mean_change", "lm_mean_cov", "multi_t", "obrien", "roast", "rmanova", "clda", "lda_cov")
# bonferroni rmanova and multi_t
sim2[, rmanova_p:=ifelse(rmanova_p*4>1,1,rmanova_p*4)]
sim2[, multi_t_p:=ifelse(multi_t_p*4>1,1,multi_t_p*4)]
sim2_long <- melt_it(sim2, method_list)
# add sim1 data
sim2_long <- rbind(sim1_long[effect=="0"], sim2_long)
sim2_long[, R_model := factor(as.integer(factor(paste(baseline_max, non_baseline_max, sep=", "))))]
sim2_long[, .(baseline=mean(r.baseline),
non_baseline=mean(r.nonbaseline)),
by = .(R_model)]
jco_pal1 <- pal_jco()(6)
group_colors <- c(rep(jco_pal[c(2,5,4,6)], each=3))[1:length(method_list)]
group_shapes <- c(rep(c(15, 16, 17), 4))[1:length(method_list)]
sim2_long[, d_baseline_std := abs(d_baseline)/emp.sigma]
sim2_long[, logit_p := ifelse(is.infinite(logit(p)), NA, logit(p))]
plot_data <- data.table(NULL)
new_d_baseline <- seq(0, 1.5, by=0.1) # uniform values of d_baseline_std for prediction
new_data <- data.table(d_baseline_std = new_d_baseline)
for(model_i in levels(sim2_long$R_model)){
for(method_i in method_list){
m1 <- glm(significant ~ d_baseline_std,
family = binomial(link="logit"),
data=sim2_long[method==method_i & R_model==model_i])
prob.m1 <- predict(m1, new_data, type="response")
plot_data <- rbind(plot_data, data.table(method = method_i,
R_model = model_i,
d_baseline_std = new_d_baseline,
prob.m1=prob.m1))
}
}
plot_data[, method := factor(method, method_list)]
gg1 <- ggplot(data=plot_data,
aes(x=d_baseline_std, y=prob.m1, color=method, shape=method)) +
geom_hline(yintercept = 0.05, linetype = "dashed", alpha=0.5) +
geom_point() +
geom_line() +
scale_color_manual(values = group_colors) +
scale_shape_manual(values = group_shapes) +
ylab("Probability of p < 0.05") +
xlab("Difference at Time0 (in standard deviation units)") +
theme_pubr() +
theme(legend.position="top") +
guides(col = guide_legend(ncol = 4)) +
facet_grid(.~R_model, labeller = "label_both") +
NULL
gg1
fn <- "simulation-4.dyUoA.Rds"
file_path <- here(output_path, fn)
sim4 <- data.table(readRDS(file_path))
sim4[, lm_mean_cov_alpha_p:=NULL]
# add simulation 1
fn <- "simulation-1.Le6N9.Rds"
file_path <- here(output_path, fn)
sim1b <- data.table(readRDS(file_path))[effect=="0"]
sim1b[, effect_model:="no pre"]
sim4 <- rbind(sim4, sim1b)
sim4[, effect_model := factor(effect_model)]
method_list <- c("lm_area", "lm_base", "lm_cov", "lm_mean", "lm_mean_change", "lm_mean_cov", "multi_t",  "rmanova", "clda", "lda_cov", "obrien", "roast")
# bonferroni rmanova and multi_t
sim4[, rmanova_p:=ifelse(rmanova_p*4>1,1,rmanova_p*4)]
sim4[, multi_t_p:=ifelse(multi_t_p*4>1,1,multi_t_p*4)]
sim4_long <- melt_it(sim4, method_list)
sim4_long[!is.na(p), .(freq_lt_05 = sum(p < 0.05)/max(iter)),
by=.(effect_model, method)]
jco_pal <- pal_jco()(6)
group_colors <- c(rep(jco_pal[c(2,5,4,6)], each=3))[1:length(method_list)]
group_shapes <- c(rep(c(15, 16, 17), 4))[1:length(method_list)]
sim4_long[, d_baseline_std := abs(d_baseline)/emp.sigma]
sim4_long[, logit_p := ifelse(is.infinite(logit(p)), NA, logit(p))]
plot_data <- data.table(NULL)
new_d_baseline <- seq(0, 1.5, by=0.1) # uniform values of d_baseline_std for prediction
new_data <- data.table(d_baseline_std = new_d_baseline)
for(model_i in levels(sim4_long$effect_model)){
for(method_i in method_list){
m1 <- glm(significant ~ d_baseline_std,
family = binomial(link="logit"),
data=sim4_long[method==method_i & effect_model==model_i])
prob.m1 <- predict(m1, new_data, type="response")
plot_data <- rbind(plot_data, data.table(method = method_i,
effect_model = model_i,
d_baseline_std = new_d_baseline,
prob.m1=prob.m1))
}
}
plot_data[, method := factor(method, method_list)]
gg1 <- ggplot(data=plot_data,
aes(x=d_baseline_std, y=prob.m1, color=method, shape=method)) +
geom_hline(yintercept = 0.05, linetype = "dashed", alpha=0.5) +
geom_point() +
geom_line() +
scale_color_manual(values = group_colors) +
scale_shape_manual(values = group_shapes) +
ylab("Probability of p < 0.05") +
xlab("Difference at Time0 (in standard deviation units)") +
theme_pubr() +
theme(legend.position="top") +
guides(col = guide_legend(ncol = 4)) +
facet_grid(.~effect_model, labeller = "label_both") +
NULL
gg1
169*2.54
50*2.54
9*2.54
19.5*2.54
69*2.54
37/2.54
60/2.54
80/2.54
