sim_stats_cols <- c("d_baseline", p_cols)
sim_stats <- matrix(NA, nrow=niter, ncol=length(sim_stats_cols))
colnames(sim_stats) <- sim_stats_cols
n.times <- length(times)
p.clda <- n.times*2 - 2
# change names of mu (which will change colnames of Y)
names(mu) <- paste0("glucose", times)
# for Roast and Obrien
xcols <- c("treatment", "glucose0")
zcols <- "treatment"
roast_form <- formula(paste('~',paste(xcols,collapse='+'),sep=''))
# init fake data matrix
fd <- data.table(treatment=factor(rep(c("cn", "tr"), each=n)))
fd[, id:=factor(1:.N)]
for(iter in 1:niter){
Y <- rbind(rmvnorm(n, mu, Sigma),
rmvnorm(n, mu+beta, Sigma))
fd[, glucose_0 := Y[,1]]
#fd[, area := apply(Y, 1, auc, x=times)]
fd[, area := apply(Y, 1, trap.rule, x=times)] # faster because compiled?
#fd[, area_base := apply(Y, 1, auc, x=times, baseline=TRUE)]
fd[, area_base := apply(Y-Y[,1], 1, trap.rule, x=times)]
fd[, glucose_mean := apply(Y[,-1], 1, mean)]
fd[, glucose_change := glucose_mean - glucose_0]
fd_wide <- cbind(fd, Y)
fd_long <- melt(fd_wide, id.vars=c("treatment", "id", "glucose_0"),
measure.vars = paste0("glucose", times),
variable.name = "time",
value.name = "glucose")
fd_long[, time:=factor(time)]
sim_stats[iter, "d_baseline"] <- mean(Y[1:n, 1]) - mean(Y[(n+1):(2*n), 1])
if("lm_area" %in% method_list){
m1 <- lm(area ~ treatment, data=fd)
sim_stats[iter, "lm_area_p"] <- coef(summary(m1))["treatmenttr","Pr(>|t|)"]
#sim_stats[iter, "lm_area_b"] <- coef(m1)["treatmenttr"]
}
if("lm_base" %in% method_list){
m2 <- lm(area_base ~ treatment, data=fd)
sim_stats[iter, "lm_base_p"] <- coef(summary(m2))["treatmenttr","Pr(>|t|)"]
#sim_stats[iter, "lm_base_b"] <- coef(m2)["treatmenttr"]
}
if("lm_cov" %in% method_list){
m3 <- lm(area ~ treatment + glucose_0, data=fd)
sim_stats[iter, "lm_cov_p"] <- coef(summary(m3))["treatmenttr","Pr(>|t|)"]
#sim_stats[iter, "lm_cov_b"] <- coef(m3)["treatmenttr"]
}
if("lm_mean" %in% method_list){
m4 <- lm(glucose_mean ~ treatment, data=fd)
sim_stats[iter, "lm_mean_p"] <- coef(summary(m4))["treatmenttr","Pr(>|t|)"]
#sim_stats[iter, "lm_mean_b"] <- coef(m4)["treatmenttr"]
}
if("lm_mean_cov" %in% method_list){
m5 <- lm(glucose_mean ~ treatment + glucose_0, data=fd)
sim_stats[iter, "lm_mean_cov_p"] <- coef(summary(m5))["treatmenttr","Pr(>|t|)"]
#sim_stats[iter, "lm_mean_cov_b"] <- coef(m5)["treatmenttr"]
}
if("lm_mean_change" %in% method_list){
m6 <- lm(glucose_change ~ treatment, data=fd)
sim_stats[iter, "lm_mean_change_p"] <- coef(summary(m6))["treatmenttr","Pr(>|t|)"]
#sim_stats[iter, "lm_mean_change_b"] <- coef(m6)["treatmenttr"]
}
if("rmanova" %in% method_list |
"rmanova.i" %in% method_list |
"rmanova.t" %in% method_list){
# rmanova returns the smallest unadjusted p of the pairs
# rmanova.i returns the p for the anova interaction
# rmanova.t returns the p for the anova treatment
m7 <- aov_4(glucose ~ time*treatment + (time|id),
data=fd_long)
if("rmanova" %in% method_list){
m7.emm <- emmeans(m7,  ~ treatment*time)
sim_stats[iter, "rmanova_p"] <- min(summary(emmeans::contrast(m7.emm,
method = "revpairwise",
simple = "each",
combine = TRUE,
adjust = "none"))[2:n.times, "p.value"])
}
if("rmanova.i" %in% method_list){
sim_stats[iter, "rmanova.i_p"] <- m7$anova_table["treatment:time", "Pr(>F)"]}
if("rmanova.t" %in% method_list){
sim_stats[iter, "rmanova.t_p"] <- m7$anova_table["treatment", "Pr(>F)"]}
}
if("multi_t" %in% method_list){
Yy <- Y[, -1]
fit <- lm(Yy ~ treatment, data=fd_wide)
sim_stats[iter, "multi_t_p"] <- min(
coefficients(summary(fit))[[1]]["treatmenttr","Pr(>|t|)"],
coefficients(summary(fit))[[2]]["treatmenttr","Pr(>|t|)"],
coefficients(summary(fit))[[3]]["treatmenttr","Pr(>|t|)"],
coefficients(summary(fit))[[4]]["treatmenttr","Pr(>|t|)"]
)
#sim_stats[iter, "multi_t_b"] <- NA
}
if("clda" %in% method_list){
# clda
#      design <- model.matrix( ~ time + treatment:time, data=fd_long)
# remove intercept column and effect of tr at time 0
#      X <- design[, -c(1, which(colnames(design) == "timeglucose0:treatmenttr"))]
# first check equivalence with single post baseline time
check_equivalence <- FALSE
if(check_equivalence == TRUE){
inc <- which(fd_long$time=="glucose0" | fd_long$time=="glucose15")
X.check <- design[inc, c(2,7)]
m8a <- gls(glucose ~ X.check, # clda
data = fd_long[time=="glucose0" | time=="glucose15"],
weights = varIdent(form= ~ 1 | time),
correlation= corSymm(form=~ 1| id)
)
m8b <- lm(glucose ~ glucose_0 + treatment, # ancova-like
data = fd_long[time=="glucose15"]
)
coef(summary(m8a))
coef(summary(m8b))
# note that clda has smaller SE.
# from https://datascienceplus.com/taking-the-baseline-measurement-into-account-constrained-lda-in-r/. By setting weights = varIdent(form = ~ 1 | Time) a separate standard deviation will be estimated for each time point and a seperate correlation will be estimated for each pair of time points (= unstructured variance covariance matrix). By setting weights = varIdent(form = ~ 1 | Time:Group), a separate variance is estimated for each combination of Group and Time (Pre-Exp Post-Exp Pre-Con Post-Con ). The argument correlation=corSymm (form = ~ 1 | Id) defines the subject levels. The correlation structure is assumed to apply only to observations within the same subject (in our example: Id); observations from different subjects (a different value for Id) are assumed to be uncorrelated.
}
#      m8 <- gls(glucose ~ X,
#                 data = fd_long,
#                 weights = varIdent(form= ~ 1 | time),
#                 correlation= corSymm(form=~ 1| id))
# # an alternative that gives same results. Simply code the interaction columns into a factor
fd_clda <- copy(fd_long)
fd_clda[, time.treatment := ifelse(time != "glucose0" & treatment=="tr", paste0(time, ":tr"), "cont")]
fd_clda[, time.treatment := factor(time.treatment, c("cont","glucose15:tr", "glucose30:tr",  "glucose60:tr", "glucose120:tr"))]
m8 <- gls(glucose ~ time + time.treatment,
data = fd_clda,
weights = varIdent(form= ~ 1 | time),
correlation= corSymm(form=~ 1| id))
r_fit <- cov2cor(getVarCov(m8))
r_bar <- mean(r_fit[upper.tri(r_fit)])
m <- round(5*n*2/(1 + r_bar*(5-1)), 0)
#m8.z <- summary(glht(m8, matrix(c(0, 0,0,0,0,1,1,1,1), 1)))
m8.t <- summary(glht(m8,
matrix(c(0, 0,0,0,0,1,1,1,1), 1),
df = m - p.clda))
sim_stats[iter, "clda_p"] <- m8.t$test$pvalues
#sim_stats[iter, "clda_b"] <- m8.t$test$coefficients/4
}
if("lda_cov" %in% method_list){
subdata <- fd_long[time != "glucose0"] # needed for emmeans
m9 <- gls(glucose ~ time*treatment + glucose_0,
data = subdata,
weights = varIdent(form= ~ 1 | time),
correlation= corSymm(form=~ 1 | id))
# note interaction coefficients are not effects at times 30, 60, 120
# but differences in effect from that at time 15. This is *not* what we want.
m9.emm <- emmeans(m9,
specs=c("treatment"),
#                      mode = "boot-satterthwaite",
mode = "df.error",
data = subdata)
m9.trt <- emmeans::contrast(m9.emm, method="revpairwise")
sim_stats[iter, "lda_cov_p"] <- summary(m9.trt)[, "p.value"]
#sim_stats[iter, "lda_cov_b"] <- summary(m9.trt)[, "estimate"]
}
if("roast" %in% method_list){
Yt <- t(Y[, -1]) # responses in rows
design <- model.matrix(roast_form, data=fd_wide)
colnames(design)[1] <- 'Intercept' # change '(Intercept)' to 'Intercept'
prob <- roast(y=Yt,design=design,contrast=2, nrot=2000)$p['UpOrDown','P.Value']
sim_stats[iter, "roast_p"] <- roast(y=Yt,design=design,contrast=2, nrot=2000)$p['UpOrDown','P.Value']
#sim_stats[iter, "roast_b"] <- NA
# cont.matrix <- makeContrasts(delta="zhedonia-zeudaimonia",levels=design)
# prob['delta'] <- roast(y=Yt,design=design,contrast=cont.matrix, nrot=perms)$p['UpOrDown','P.Value']
}
if("obrien" %in% method_list){
Yy <- Y[, -1]
# design matrix for obrien
X2 <- model.matrix(~ glucose0, data=fd_wide)
XTXI <- solve(t(X2)%*%X2)
fit <- lm.fit(X2, Yy)
e <- fit$residuals
ranks <- apply(e, 2, rank)
ranksum <- apply(ranks, 1, sum)
obrien.p <- t.test(ranksum ~ fd_wide$treatment, var.equal=TRUE)$p.value
# wilcox.test(ranksum ~ fd_wide$treatment)
# rank2 <- apply(e, 1, sum)
# wilcox.test(rank2 ~ fd_wide$treatment)
sim_stats[iter, "obrien_p"] <- obrien.p
#sim_stats[iter, "obrien_b"] <- NA
}
}
return(sim_stats)
}
simulation_wrapper <- function(
niter = 1000,
n = 5,
method_list,
times = c(0, 15, 30, 60, 120),
gtt_effects = c(0, 1, 1, 1, 0),
mu,
sigma,
cohen_list = c(0, 0.8, 2),
cor_models
){
p <- length(times)
combis <- expand.grid(cohen = cohen_list, cor_model = 1:nrow(cor_models))
for(i in 1:nrow(combis)){
cohen <- combis[i, "cohen"]
baseline_max <- cor_models[combis[i, "cor_model"], "baseline_max"]
non_baseline_max <- cor_models[combis[i, "cor_model"], "non_baseline_max"]
R <- fake_Rho(p,
rho.base.2 = baseline_max,
rho.base.p = 3/4*baseline_max,
rho.max.max = non_baseline_max,
rho.max.min = 7/8*non_baseline_max,
rho.min = 5/8*non_baseline_max)
R_0 <- R[,1] # correlation of each time with time0
R_0[1] <- 0 # don't add this component to first beta
Sigma <- diag(sigma)%*%R%*%diag(sigma)
beta <- gtt_effects*cohen*sigma + R_0*sigma*gtt_effects[1]*cohen
sim_stats <- simulate_it(n = n,
mu = mu,
beta = beta,
Sigma = Sigma,
times = times,
niter = niter,
method_list = method_list)
res <- rbind(res, data.table(iter = 1:niter,
effect = cohen,
baseline_max = baseline_max,
non_baseline_max = non_baseline_max,
data.table(sim_stats)))
}
res[, effect := factor(effect)]
res[, baseline_max := factor(baseline_max)]
res[, non_baseline_max := factor(non_baseline_max)]
return(res)
}
res <- simulation_wrapper(
niter = niter,
n = n,
method_list,
times = times,
gtt_effects = gtt_effects,
mu = mu,
sigma = emp.sigma,
cohen_list = cohen_list,
cor_models
)
rho.1.2 <- 0.5
rho.1.p <- 0.6
rho.max.max <- 0.8
rho.max.min <- 0.7
fake_Rho <- function(p=5,
rho.base.2 = 0.6,
rho.base.p = 0.5,
rho.max.max = 0.8,
rho.max.min = 0.7,
rho.min = 0.5){
# rho.base.2 and rho.base.p control the correlations of baseline with post-baseline measures. These tend to be lower than the correlations among post-baseline measures, generally between 0 and 0.5
# rho.max.max and rho.max.min control the maximum post-baseline correlations. In general the correlations are highest beteween succeesive times and are highest between final two times, which is rho.max.max. rho.max.min is the correlation between time 2 and 3. The correlations drop to rho.min.
Rho_fake <- matrix(1, nrow=p, ncol=p)
for(i in 1:(p-1)){
cells <- p - i
row.max <- (cells-1)/(p-2-1)*rho.max.min + (1-(cells-1)/(p-2-1))*rho.max.max
inc <- -(row.max - rho.min)/(p - 2 -1)
for(j in (i+1):p){
if(i==1){
Rho_fake[i,j] <- (j-2)/(p-2)*rho.base.p + (1-(j-2)/(p-2))*rho.base.2
Rho_fake[j,i] <- Rho_fake[i,j]
}else{
Rho_fake[i,j] <- row.max + inc*(cells - (p-j+1))
Rho_fake[j,i] <- Rho_fake[i,j]
}
}
}
return(Rho_fake)
}
simulate_it <- function(n=5, mu, beta, Sigma, times, niter=1000, method_list){
p_cols <- paste0(method_list, "_p")
b_cols <- paste0(method_list, "_b")
sim_stats_cols <- c("d_baseline", p_cols)
sim_stats <- matrix(NA, nrow=niter, ncol=length(sim_stats_cols))
colnames(sim_stats) <- sim_stats_cols
n.times <- length(times)
p.clda <- n.times*2 - 2
# change names of mu (which will change colnames of Y)
names(mu) <- paste0("glucose", times)
# for Roast and Obrien
xcols <- c("treatment", "glucose0")
zcols <- "treatment"
roast_form <- formula(paste('~',paste(xcols,collapse='+'),sep=''))
# init fake data matrix
fd <- data.table(treatment=factor(rep(c("cn", "tr"), each=n)))
fd[, id:=factor(1:.N)]
for(iter in 1:niter){
Y <- rbind(rmvnorm(n, mu, Sigma),
rmvnorm(n, mu+beta, Sigma))
fd[, glucose_0 := Y[,1]]
#fd[, area := apply(Y, 1, auc, x=times)]
fd[, area := apply(Y, 1, trap.rule, x=times)] # faster because compiled?
#fd[, area_base := apply(Y, 1, auc, x=times, baseline=TRUE)]
fd[, area_base := apply(Y-Y[,1], 1, trap.rule, x=times)]
fd[, glucose_mean := apply(Y[,-1], 1, mean)]
fd[, glucose_change := glucose_mean - glucose_0]
fd_wide <- cbind(fd, Y)
fd_long <- melt(fd_wide, id.vars=c("treatment", "id", "glucose_0"),
measure.vars = paste0("glucose", times),
variable.name = "time",
value.name = "glucose")
fd_long[, time:=factor(time)]
sim_stats[iter, "d_baseline"] <- mean(Y[1:n, 1]) - mean(Y[(n+1):(2*n), 1])
if("lm_area" %in% method_list){
m1 <- lm(area ~ treatment, data=fd)
sim_stats[iter, "lm_area_p"] <- coef(summary(m1))["treatmenttr","Pr(>|t|)"]
#sim_stats[iter, "lm_area_b"] <- coef(m1)["treatmenttr"]
}
if("lm_base" %in% method_list){
m2 <- lm(area_base ~ treatment, data=fd)
sim_stats[iter, "lm_base_p"] <- coef(summary(m2))["treatmenttr","Pr(>|t|)"]
#sim_stats[iter, "lm_base_b"] <- coef(m2)["treatmenttr"]
}
if("lm_cov" %in% method_list){
m3 <- lm(area ~ treatment + glucose_0, data=fd)
sim_stats[iter, "lm_cov_p"] <- coef(summary(m3))["treatmenttr","Pr(>|t|)"]
#sim_stats[iter, "lm_cov_b"] <- coef(m3)["treatmenttr"]
}
if("lm_mean" %in% method_list){
m4 <- lm(glucose_mean ~ treatment, data=fd)
sim_stats[iter, "lm_mean_p"] <- coef(summary(m4))["treatmenttr","Pr(>|t|)"]
#sim_stats[iter, "lm_mean_b"] <- coef(m4)["treatmenttr"]
}
if("lm_mean_cov" %in% method_list){
m5 <- lm(glucose_mean ~ treatment + glucose_0, data=fd)
sim_stats[iter, "lm_mean_cov_p"] <- coef(summary(m5))["treatmenttr","Pr(>|t|)"]
#sim_stats[iter, "lm_mean_cov_b"] <- coef(m5)["treatmenttr"]
}
if("lm_mean_change" %in% method_list){
m6 <- lm(glucose_change ~ treatment, data=fd)
sim_stats[iter, "lm_mean_change_p"] <- coef(summary(m6))["treatmenttr","Pr(>|t|)"]
#sim_stats[iter, "lm_mean_change_b"] <- coef(m6)["treatmenttr"]
}
if("rmanova" %in% method_list |
"rmanova.i" %in% method_list |
"rmanova.t" %in% method_list){
# rmanova returns the smallest unadjusted p of the pairs
# rmanova.i returns the p for the anova interaction
# rmanova.t returns the p for the anova treatment
m7 <- aov_4(glucose ~ time*treatment + (time|id),
data=fd_long)
if("rmanova" %in% method_list){
m7.emm <- emmeans(m7,  ~ treatment*time)
sim_stats[iter, "rmanova_p"] <- min(summary(emmeans::contrast(m7.emm,
method = "revpairwise",
simple = "each",
combine = TRUE,
adjust = "none"))[2:n.times, "p.value"])
}
if("rmanova.i" %in% method_list){
sim_stats[iter, "rmanova.i_p"] <- m7$anova_table["treatment:time", "Pr(>F)"]}
if("rmanova.t" %in% method_list){
sim_stats[iter, "rmanova.t_p"] <- m7$anova_table["treatment", "Pr(>F)"]}
}
if("multi_t" %in% method_list){
Yy <- Y[, -1]
fit <- lm(Yy ~ treatment, data=fd_wide)
sim_stats[iter, "multi_t_p"] <- min(
coefficients(summary(fit))[[1]]["treatmenttr","Pr(>|t|)"],
coefficients(summary(fit))[[2]]["treatmenttr","Pr(>|t|)"],
coefficients(summary(fit))[[3]]["treatmenttr","Pr(>|t|)"],
coefficients(summary(fit))[[4]]["treatmenttr","Pr(>|t|)"]
)
#sim_stats[iter, "multi_t_b"] <- NA
}
if("clda" %in% method_list){
# clda
#      design <- model.matrix( ~ time + treatment:time, data=fd_long)
# remove intercept column and effect of tr at time 0
#      X <- design[, -c(1, which(colnames(design) == "timeglucose0:treatmenttr"))]
# first check equivalence with single post baseline time
check_equivalence <- FALSE
if(check_equivalence == TRUE){
inc <- which(fd_long$time=="glucose0" | fd_long$time=="glucose15")
X.check <- design[inc, c(2,7)]
m8a <- gls(glucose ~ X.check, # clda
data = fd_long[time=="glucose0" | time=="glucose15"],
weights = varIdent(form= ~ 1 | time),
correlation= corSymm(form=~ 1| id)
)
m8b <- lm(glucose ~ glucose_0 + treatment, # ancova-like
data = fd_long[time=="glucose15"]
)
coef(summary(m8a))
coef(summary(m8b))
# note that clda has smaller SE.
# from https://datascienceplus.com/taking-the-baseline-measurement-into-account-constrained-lda-in-r/. By setting weights = varIdent(form = ~ 1 | Time) a separate standard deviation will be estimated for each time point and a seperate correlation will be estimated for each pair of time points (= unstructured variance covariance matrix). By setting weights = varIdent(form = ~ 1 | Time:Group), a separate variance is estimated for each combination of Group and Time (Pre-Exp Post-Exp Pre-Con Post-Con ). The argument correlation=corSymm (form = ~ 1 | Id) defines the subject levels. The correlation structure is assumed to apply only to observations within the same subject (in our example: Id); observations from different subjects (a different value for Id) are assumed to be uncorrelated.
}
#      m8 <- gls(glucose ~ X,
#                 data = fd_long,
#                 weights = varIdent(form= ~ 1 | time),
#                 correlation= corSymm(form=~ 1| id))
# # an alternative that gives same results. Simply code the interaction columns into a factor
fd_clda <- copy(fd_long)
fd_clda[, time.treatment := ifelse(time != "glucose0" & treatment=="tr", paste0(time, ":tr"), "cont")]
fd_clda[, time.treatment := factor(time.treatment, c("cont","glucose15:tr", "glucose30:tr",  "glucose60:tr", "glucose120:tr"))]
m8 <- gls(glucose ~ time + time.treatment,
data = fd_clda,
weights = varIdent(form= ~ 1 | time),
correlation= corSymm(form=~ 1| id))
r_fit <- cov2cor(getVarCov(m8))
r_bar <- mean(r_fit[upper.tri(r_fit)])
m <- round(5*n*2/(1 + r_bar*(5-1)), 0)
#m8.z <- summary(glht(m8, matrix(c(0, 0,0,0,0,1,1,1,1), 1)))
m8.t <- summary(glht(m8,
matrix(c(0, 0,0,0,0,1,1,1,1), 1),
df = m - p.clda))
sim_stats[iter, "clda_p"] <- m8.t$test$pvalues
#sim_stats[iter, "clda_b"] <- m8.t$test$coefficients/4
}
if("lda_cov" %in% method_list){
subdata <- fd_long[time != "glucose0"] # needed for emmeans
m9 <- gls(glucose ~ time*treatment + glucose_0,
data = subdata,
weights = varIdent(form= ~ 1 | time),
correlation= corSymm(form=~ 1 | id))
# note interaction coefficients are not effects at times 30, 60, 120
# but differences in effect from that at time 15. This is *not* what we want.
m9.emm <- emmeans(m9,
specs=c("treatment"),
mode = "boot-satterthwaite",
#                      mode = "df.error",
data = subdata)
m9.trt <- emmeans::contrast(m9.emm, method="revpairwise")
sim_stats[iter, "lda_cov_p"] <- summary(m9.trt)[, "p.value"]
#sim_stats[iter, "lda_cov_b"] <- summary(m9.trt)[, "estimate"]
}
if("roast" %in% method_list){
Yt <- t(Y[, -1]) # responses in rows
design <- model.matrix(roast_form, data=fd_wide)
colnames(design)[1] <- 'Intercept' # change '(Intercept)' to 'Intercept'
prob <- roast(y=Yt,design=design,contrast=2, nrot=2000)$p['UpOrDown','P.Value']
sim_stats[iter, "roast_p"] <- roast(y=Yt,design=design,contrast=2, nrot=2000)$p['UpOrDown','P.Value']
#sim_stats[iter, "roast_b"] <- NA
# cont.matrix <- makeContrasts(delta="zhedonia-zeudaimonia",levels=design)
# prob['delta'] <- roast(y=Yt,design=design,contrast=cont.matrix, nrot=perms)$p['UpOrDown','P.Value']
}
if("obrien" %in% method_list){
Yy <- Y[, -1]
# design matrix for obrien
X2 <- model.matrix(~ glucose0, data=fd_wide)
XTXI <- solve(t(X2)%*%X2)
fit <- lm.fit(X2, Yy)
e <- fit$residuals
ranks <- apply(e, 2, rank)
ranksum <- apply(ranks, 1, sum)
obrien.p <- t.test(ranksum ~ fd_wide$treatment, var.equal=TRUE)$p.value
# wilcox.test(ranksum ~ fd_wide$treatment)
# rank2 <- apply(e, 1, sum)
# wilcox.test(rank2 ~ fd_wide$treatment)
sim_stats[iter, "obrien_p"] <- obrien.p
#sim_stats[iter, "obrien_b"] <- NA
}
}
return(sim_stats)
}
simulation_wrapper <- function(
niter = 1000,
n = 5,
method_list,
times = c(0, 15, 30, 60, 120),
gtt_effects = c(0, 1, 1, 1, 0),
mu,
sigma,
cohen_list = c(0, 0.8, 2),
cor_models
){
p <- length(times)
combis <- expand.grid(cohen = cohen_list, cor_model = 1:nrow(cor_models))
for(i in 1:nrow(combis)){
cohen <- combis[i, "cohen"]
baseline_max <- cor_models[combis[i, "cor_model"], "baseline_max"]
non_baseline_max <- cor_models[combis[i, "cor_model"], "non_baseline_max"]
R <- fake_Rho(p,
rho.base.2 = baseline_max,
rho.base.p = 3/4*baseline_max,
rho.max.max = non_baseline_max,
rho.max.min = 7/8*non_baseline_max,
rho.min = 5/8*non_baseline_max)
R_0 <- R[,1] # correlation of each time with time0
R_0[1] <- 0 # don't add this component to first beta
Sigma <- diag(sigma)%*%R%*%diag(sigma)
beta <- gtt_effects*cohen*sigma + R_0*sigma*gtt_effects[1]*cohen
sim_stats <- simulate_it(n = n,
mu = mu,
beta = beta,
Sigma = Sigma,
times = times,
niter = niter,
method_list = method_list)
res <- rbind(res, data.table(iter = 1:niter,
effect = cohen,
baseline_max = baseline_max,
non_baseline_max = non_baseline_max,
data.table(sim_stats)))
}
res[, effect := factor(effect)]
res[, baseline_max := factor(baseline_max)]
res[, non_baseline_max := factor(non_baseline_max)]
return(res)
}
res <- simulation_wrapper(
niter = niter,
n = n,
method_list,
times = times,
gtt_effects = gtt_effects,
mu = mu,
sigma = emp.sigma,
cohen_list = cohen_list,
cor_models
)
